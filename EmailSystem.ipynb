{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujPDDG3QjWYm",
        "outputId": "bbcd0aed-f4d1-449e-b49f-22c90415047a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "academic_collaboration       0.67      1.00      0.80         2\n",
            "     corporate_inquiry       0.00      0.00      0.00         1\n",
            "       student_inquiry       1.00      1.00      1.00         1\n",
            "\n",
            "              accuracy                           0.75         4\n",
            "             macro avg       0.56      0.67      0.60         4\n",
            "          weighted avg       0.58      0.75      0.65         4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Expanded dataset to balance classes\n",
        "data = {\n",
        "    'email_text': [\n",
        "        \"Can you send me the syllabus for my course?\",\n",
        "        \"I need to discuss a research partnership between our institutions.\",\n",
        "        \"I'd like to know about internship opportunities at your department.\",\n",
        "        \"I need help with accessing the course materials.\",\n",
        "        \"Our company would like to offer placement opportunities.\",\n",
        "        \"I'm reaching out to discuss a potential academic cooperation.\",\n",
        "        \"I'm having trouble enrolling in the online course.\",\n",
        "        \"We'd like to collaborate on research data sharing.\",\n",
        "        \"Is there a way to apply for internships?\",\n",
        "        \"Please help me with my course grades.\",\n",
        "        \"I want to request a transcript.\",\n",
        "        \"Can you help me with exam dates?\",\n",
        "        \"We'd like to discuss a research project.\",\n",
        "        \"We are interested in a joint academic conference.\",\n",
        "        \"Could you send me details on internship programs?\",\n",
        "        \"We need a student internship program proposal.\",\n",
        "        \"How can I collaborate on research in your lab?\",\n",
        "        \"Can I use your research facilities?\"\n",
        "    ],\n",
        "    'label': [\n",
        "        'student_inquiry', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'student_inquiry', 'corporate_inquiry', 'academic_collaboration',\n",
        "        'student_inquiry', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'student_inquiry', 'student_inquiry', 'student_inquiry',\n",
        "        'academic_collaboration', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'corporate_inquiry', 'academic_collaboration', 'academic_collaboration'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features and labels\n",
        "X = df['email_text']\n",
        "y = df['label']\n",
        "\n",
        "# Use stratified split to preserve class distribution\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Display the classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Expanded dataset to balance classes\n",
        "data = {\n",
        "    'email_text': [\n",
        "        \"Can you send me the syllabus for my course?\",\n",
        "        \"I need to discuss a research partnership between our institutions.\",\n",
        "        \"I'd like to know about internship opportunities at your department.\",\n",
        "        \"I need help with accessing the course materials.\",\n",
        "        \"Our company would like to offer placement opportunities.\",\n",
        "        \"I'm reaching out to discuss a potential academic cooperation.\",\n",
        "        \"I'm having trouble enrolling in the online course.\",\n",
        "        \"We'd like to collaborate on research data sharing.\",\n",
        "        \"Is there a way to apply for internships?\",\n",
        "        \"Please help me with my course grades.\",\n",
        "        \"I want to request a transcript.\",\n",
        "        \"Can you help me with exam dates?\",\n",
        "        \"We'd like to discuss a research project.\",\n",
        "        \"We are interested in a joint academic conference.\",\n",
        "        \"Could you send me details on internship programs?\",\n",
        "        \"We need a student internship program proposal.\",\n",
        "        \"How can I collaborate on research in your lab?\",\n",
        "        \"Can I use your research facilities?\",\n",
        "        \"This is a confidential partnership proposal.\",\n",
        "        \"We would like to explore legal aspects of our collaboration.\"\n",
        "    ],\n",
        "    'label': [\n",
        "        'student_inquiry', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'student_inquiry', 'corporate_inquiry', 'academic_collaboration',\n",
        "        'student_inquiry', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'student_inquiry', 'student_inquiry', 'student_inquiry',\n",
        "        'academic_collaboration', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'corporate_inquiry', 'academic_collaboration', 'academic_collaboration',\n",
        "        'corporate_inquiry', 'corporate_inquiry'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features and labels\n",
        "X = df['email_text']\n",
        "y = df['label']\n",
        "\n",
        "# Use stratified split to preserve class distribution\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Display the classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Email Routing and Handling\n",
        "sensitive_keywords = ['confidential', 'partnership', 'legal', 'agreement']\n",
        "\n",
        "def handle_email(email_text, classification):\n",
        "    \"\"\"\n",
        "    Routes and handles emails based on their classification and content.\n",
        "    \"\"\"\n",
        "    # Check if the email contains sensitive keywords\n",
        "    if classification == 'corporate_inquiry' or any(word in email_text.lower() for word in sensitive_keywords):\n",
        "        return f\"[Escalated for manual response] {email_text}\"\n",
        "    else:\n",
        "        return f\"[Auto Response Sent] {email_text}\"\n",
        "\n",
        "# Simulate routing of test emails\n",
        "print(\"\\nEmail Routing & Handling:\\n\")\n",
        "for email, label in zip(X_test, y_pred):\n",
        "    result = handle_email(email, label)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkwQmqaXfHla",
        "outputId": "cc22ae48-4507-44e7-bdfa-c2f831cb43bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "academic_collaboration       1.00      1.00      1.00         2\n",
            "     corporate_inquiry       0.50      1.00      0.67         1\n",
            "       student_inquiry       0.00      0.00      0.00         1\n",
            "\n",
            "              accuracy                           0.75         4\n",
            "             macro avg       0.50      0.67      0.56         4\n",
            "          weighted avg       0.62      0.75      0.67         4\n",
            "\n",
            "\n",
            "Email Routing & Handling:\n",
            "\n",
            "[Auto Response Sent] We'd like to discuss a research project.\n",
            "[Auto Response Sent] We are interested in a joint academic conference.\n",
            "[Escalated for manual response] I want to request a transcript.\n",
            "[Escalated for manual response] We would like to explore legal aspects of our collaboration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'email_text': [\n",
        "        \"Can you send me the syllabus for my course?\",\n",
        "        \"I need to discuss a research partnership between our institutions.\",\n",
        "        \"I'd like to know about internship opportunities at your department.\",\n",
        "        \"I need help with accessing the course materials.\",\n",
        "        \"Our company would like to offer placement opportunities.\",\n",
        "        \"I'm reaching out to discuss a potential academic cooperation.\",\n",
        "        \"I'm having trouble enrolling in the online course.\",\n",
        "        \"We'd like to collaborate on research data sharing.\",\n",
        "        \"Is there a way to apply for internships?\",\n",
        "        \"Please help me with my course grades.\",\n",
        "        \"I want to request a transcript.\",\n",
        "        \"Can you help me with exam dates?\",\n",
        "        \"We'd like to discuss a research project.\",\n",
        "        \"We are interested in a joint academic conference.\",\n",
        "        \"Could you send me details on internship programs?\",\n",
        "        \"We need a student internship program proposal.\",\n",
        "        \"How can I collaborate on research in your lab?\",\n",
        "        \"Can I use your research facilities?\",\n",
        "        \"This is a confidential partnership proposal.\",\n",
        "        \"We would like to explore legal aspects of our collaboration.\"\n",
        "    ],\n",
        "    'label': [\n",
        "        'student_inquiry', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'student_inquiry', 'corporate_inquiry', 'academic_collaboration',\n",
        "        'student_inquiry', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'student_inquiry', 'student_inquiry', 'student_inquiry',\n",
        "        'academic_collaboration', 'academic_collaboration', 'corporate_inquiry',\n",
        "        'corporate_inquiry', 'academic_collaboration', 'academic_collaboration',\n",
        "        'corporate_inquiry', 'corporate_inquiry'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features and labels\n",
        "X = df['email_text']\n",
        "y = df['label']\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Naive Bayes Classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Sensitive keywords for corporate inquiries\n",
        "sensitive_keywords = ['confidential', 'partnership', 'legal', 'agreement', 'contract']\n",
        "\n",
        "# Improved auto-response generator function\n",
        "def generate_response(email_text, classification):\n",
        "    \"\"\"\n",
        "    Generates a context-specific auto-response based on email classification.\n",
        "    \"\"\"\n",
        "    if classification == 'student_inquiry':\n",
        "        if 'syllabus' in email_text.lower():\n",
        "            return \"Attached is the syllabus for your course.\"\n",
        "        elif 'course materials' in email_text.lower():\n",
        "            return \"You can access the course materials from the department portal.\"\n",
        "        elif 'grades' in email_text.lower():\n",
        "            return \"Please check the student portal for your latest grades.\"\n",
        "        elif 'transcript' in email_text.lower():\n",
        "            return \"You can request your transcript through the university's online system.\"\n",
        "        elif 'exam' in email_text.lower():\n",
        "            return \"The exam schedule is available on the university's website.\"\n",
        "        else:\n",
        "            return \"Your inquiry has been received. We'll get back to you shortly.\"\n",
        "\n",
        "    elif classification == 'academic_collaboration':\n",
        "        if 'partnership' in email_text.lower():\n",
        "            return \"We would be happy to discuss a potential research partnership. Please provide more details.\"\n",
        "        elif 'conference' in email_text.lower():\n",
        "            return \"We are open to discussing joint academic conferences. Please share more information.\"\n",
        "        else:\n",
        "            return \"Thank you for reaching out. We are interested in discussing academic collaboration further.\"\n",
        "\n",
        "    elif classification == 'corporate_inquiry':\n",
        "        return \"Thank you for your corporate inquiry. Your request has been forwarded to the relevant department for review.\"\n",
        "\n",
        "    return \"Thank you for your email. We will get back to you shortly.\"\n",
        "\n",
        "# Function to handle email routing and response\n",
        "def handle_email(email_text, classification):\n",
        "    \"\"\"\n",
        "    Routes and handles emails based on their classification and content.\n",
        "    \"\"\"\n",
        "    # Check for sensitive keywords in corporate inquiries\n",
        "    if classification == 'corporate_inquiry' or any(word in email_text.lower() for word in sensitive_keywords):\n",
        "        return f\"[Escalated for manual handling] {email_text}\"\n",
        "    else:\n",
        "        # Generate an auto-response based on classification\n",
        "        response = generate_response(email_text, classification)\n",
        "        return f\"[Auto Response] {response}\"\n",
        "\n",
        "# Simulate email routing and handling for the test emails\n",
        "print(\"Email Routing & Handling:\\n\")\n",
        "for email, label in zip(X_test, y_pred):\n",
        "    result = handle_email(email, label)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXYXcXlegBhE",
        "outputId": "e2bb8e5a-b9df-4ea1-bb57-90292ca6271a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email Routing & Handling:\n",
            "\n",
            "[Auto Response] Thank you for reaching out. We are interested in discussing academic collaboration further.\n",
            "[Auto Response] We are open to discussing joint academic conferences. Please share more information.\n",
            "[Escalated for manual handling] I want to request a transcript.\n",
            "[Escalated for manual handling] We would like to explore legal aspects of our collaboration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Example templates for email generation\n",
        "student_templates = [\n",
        "    \"Dear Professor, I wanted to ask about {topic}. I missed the last class and would appreciate it if you could share the materials. Thank you!\",\n",
        "    \"Respected Sir/Madam, Could you please confirm the {topic} deadline? I’m unsure if it is due by this {time_frame}. Thank you!\",\n",
        "]\n",
        "\n",
        "academic_collab_templates = [\n",
        "    \"Dear Dr. {name}, I am working on research related to {topic} and saw your recent publication. I am interested in exploring a collaboration opportunity. Can we schedule a meeting?\",\n",
        "    \"Hello Professor, I am a researcher from {institution} and would like to inquire about using your department’s {resource}. What would be the procedure to request access?\"\n",
        "]\n",
        "\n",
        "corporate_templates = [\n",
        "    \"Dear Hiring Manager, I’m writing to ask about {topic} at your department for the summer of {year}. Could you provide details about the application process?\",\n",
        "    \"Dear Head of Department, We are interested in organizing a {event} at your university for recruitment. Please let us know the steps to proceed.\"\n",
        "]\n",
        "\n",
        "# Selection of variables\n",
        "topics = [\"course material\", \"assignment\", \"exam schedule\", \"research collaboration\", \"research facilities\"]\n",
        "time_frames = [\"Friday\", \"next Monday\", \"the upcoming weekend\"]\n",
        "names = [\"Johnson\", \"Robertson\", \"Smith\"]\n",
        "institutions = [\"XYZ University\", \"ABC Institute\"]\n",
        "resources = [\"lab facilities\", \"computing resources\", \"research equipment\"]\n",
        "events = [\"placement drive\", \"recruitment seminar\"]\n",
        "years = [\"2024\", \"2025\"]\n",
        "\n",
        "# Synonym Replacement Function\n",
        "def synonym_replacement(sentence, n=1):\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
        "\n",
        "    if len(random_word_list) == 0:\n",
        "        return sentence\n",
        "\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = wordnet.synsets(random_word)\n",
        "        synonym_words = [syn.lemmas()[0].name() for syn in synonyms if syn.lemmas()]\n",
        "        if len(synonym_words) > 0:\n",
        "            synonym = random.choice(synonym_words)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:\n",
        "            break\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# Random Deletion Function\n",
        "def random_deletion(sentence, p=0.1):\n",
        "    words = sentence.split()\n",
        "    if len(words) == 1:  # Only one word in sentence, can't delete\n",
        "        return sentence\n",
        "    remaining_words = [word for word in words if random.uniform(0, 1) > p]\n",
        "    if len(remaining_words) == 0:  # Avoid empty sentence\n",
        "        return random.choice(words)\n",
        "    return ' '.join(remaining_words)\n",
        "\n",
        "# Sentence Shuffling\n",
        "def sentence_shuffling(text):\n",
        "    sentences = text.split('. ')\n",
        "    random.shuffle(sentences)\n",
        "    return '. '.join(sentences)\n",
        "\n",
        "# Generate Random Emails\n",
        "def generate_email(category):\n",
        "    if category == 'student':\n",
        "        template = random.choice(student_templates)\n",
        "        email = template.format(\n",
        "            topic=random.choice(topics),\n",
        "            time_frame=random.choice(time_frames)\n",
        "        )\n",
        "    elif category == 'academic_collab':\n",
        "        template = random.choice(academic_collab_templates)\n",
        "        email = template.format(\n",
        "            topic=random.choice(topics),\n",
        "            name=random.choice(names),\n",
        "            institution=random.choice(institutions),\n",
        "            resource=random.choice(resources)\n",
        "        )\n",
        "    elif category == 'corporate':\n",
        "        template = random.choice(corporate_templates)\n",
        "        email = template.format(\n",
        "            topic=random.choice(topics),\n",
        "            event=random.choice(events),\n",
        "            year=random.choice(years)\n",
        "        )\n",
        "    return email\n",
        "\n",
        "# Apply augmentations\n",
        "def augment_email(email):\n",
        "    # Apply synonym replacement\n",
        "    email = synonym_replacement(email, n=2)\n",
        "    # Apply random deletion\n",
        "    email = random_deletion(email, p=0.1)\n",
        "    # Shuffle sentences\n",
        "    email = sentence_shuffling(email)\n",
        "    return email\n",
        "\n",
        "# Generate and augment emails for each category\n",
        "def generate_dataset(n_emails=10):\n",
        "    dataset = []\n",
        "    categories = ['student', 'academic_collab', 'corporate']\n",
        "\n",
        "    for _ in range(n_emails):\n",
        "        category = random.choice(categories)\n",
        "        email = generate_email(category)\n",
        "        augmented_email = augment_email(email)\n",
        "        dataset.append({'email': augmented_email, 'category': category})\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Generate and print a sample dataset\n",
        "sample_dataset = generate_dataset(n_emails=10)\n",
        "for email in sample_dataset:\n",
        "    print(f\"Email: {email['email']}\")\n",
        "    print(f\"Category: {email['category']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm9PNVGdkhY1",
        "outputId": "3faf871b-c008-4fde-8534-6ff295952bb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email: Thank you!. Dear Professor, I ask about inquiry collaboration. the last class and would appreciate it you could share materials\n",
            "Category: student\n",
            "\n",
            "Email: Dear Hiring Manager, I’m writing to ask about inquiry collaboration at your department the summer of 2025. Could you details about the application process?\n",
            "Category: corporate\n",
            "\n",
            "Email: Head Department, We are interest in organizing a recruitment seminar astatine your university for recruitment. Please let us know the steps to proceed.\n",
            "Category: corporate\n",
            "\n",
            "Email: Robertson, I am working on research related to course material and saw your recent publication. Can we schedule a meeting?. I am interested in exploring a collaboration opportunity. Dear Dr\n",
            "Category: academic_collab\n",
            "\n",
            "Email: Dear Hiring Manager, I’m writing to ask about research facilities astatine your department for the summer of 2024. Could you provide details the application process?\n",
            "Category: corporate\n",
            "\n",
            "Email: I missed the last class and would appreciate it if you share materials. Dear Professor, I wanted research facilities. Thank you!\n",
            "Category: student\n",
            "\n",
            "Email: would be the procedure to request access?. Hello Professor, am a researcher from ABC Institute and would like to inquire about exploitation department’s calculate resources\n",
            "Category: academic_collab\n",
            "\n",
            "Email: would be the procedure to request access?. Hello Professor, I am a researcher from ABC Institute and would like to inquire about using your department’s computing resources\n",
            "Category: academic_collab\n",
            "\n",
            "Email: Professor, am ampere researcher from XYZ University like to inquire about using your department’s lab facilities. would be the procedure to request access?\n",
            "Category: academic_collab\n",
            "\n",
            "Email: Dear Head of We are interest in organizing a recruitment seminar at university for recruitment. please let the steps proceed.\n",
            "Category: corporate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Sample dataset from the earlier generation step\n",
        "sample_dataset = generate_dataset(n_emails=100)\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "df = pd.DataFrame(sample_dataset)\n",
        "\n",
        "# Encode labels to numeric format\n",
        "label_mapping = {'student': 0, 'academic_collab': 1, 'corporate': 2}\n",
        "df['label'] = df['category'].map(label_mapping)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the emails and prepare inputs for BERT\n",
        "def tokenize_data(data, tokenizer, max_length=128):\n",
        "    return tokenizer(\n",
        "        list(data['email']),\n",
        "        max_length=max_length,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "# Tokenize train and test data\n",
        "train_encodings = tokenize_data(train_df, tokenizer)\n",
        "test_encodings = tokenize_data(test_df, tokenizer)\n",
        "\n",
        "train_labels = list(train_df['label'])\n",
        "test_labels = list(test_df['label'])\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "class EmailDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = EmailDataset(train_encodings, train_labels)\n",
        "test_dataset = EmailDataset(test_encodings, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Load BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        # Move batch data to GPU\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update progress bar\n",
        "        loop.set_description(f'Epoch {epoch+1}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "            true_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "    return true_labels, predictions\n",
        "\n",
        "# Evaluate on test data\n",
        "true_labels, predictions = evaluate(model, test_loader)\n",
        "\n",
        "# Print classification report\n",
        "# print(classification_report(true_labels, predictions, target_names=label_mapping.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBmlwYExlapl",
        "outputId": "147113c7-f0b3-44fb-e97b-806152f40e71"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]<ipython-input-8-da216dd71199>:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "Epoch 1: 100%|██████████| 10/10 [01:04<00:00,  6.41s/it, loss=1.09]\n",
            "Epoch 2: 100%|██████████| 10/10 [00:38<00:00,  3.89s/it, loss=0.64]\n",
            "Epoch 3: 100%|██████████| 10/10 [00:41<00:00,  4.15s/it, loss=0.293]\n",
            "Epoch 4: 100%|██████████| 10/10 [00:39<00:00,  3.94s/it, loss=0.0852]\n",
            "Epoch 5: 100%|██████████| 10/10 [00:41<00:00,  4.12s/it, loss=0.0518]\n",
            "Epoch 6: 100%|██████████| 10/10 [00:39<00:00,  3.98s/it, loss=0.0346]\n",
            "Epoch 7: 100%|██████████| 10/10 [00:39<00:00,  3.93s/it, loss=0.0162]\n",
            "Epoch 8: 100%|██████████| 10/10 [00:37<00:00,  3.78s/it, loss=0.013]\n",
            "Epoch 9: 100%|██████████| 10/10 [00:39<00:00,  3.93s/it, loss=0.00617]\n",
            "Epoch 10: 100%|██████████| 10/10 [00:39<00:00,  3.93s/it, loss=0.00884]\n"
          ]
        }
      ]
    }
  ]
}